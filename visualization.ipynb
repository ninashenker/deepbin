{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c302ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.cm as cm\n",
    "from   sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from   sklearn.manifold import TSNE, Isomap, LocallyLinearEmbedding, MDS, SpectralEmbedding\n",
    "from   sklearn.preprocessing import StandardScaler\n",
    "#!{sys.executable} -m pip install scikit-learn-extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "infectious-thousand",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "There were no tensor arguments to this function (e.g., you passed an empty list of Tensors), but no fallback function is registered for schema aten::_cat.  This usually means that this function requires a non-empty list of Tensors.  Available functions are [CPU, CUDA, QuantizedCPU, BackendSelect, Named, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradNestedTensor, UNKNOWN_TENSOR_TYPE_ID, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, Autocast, Batched, VmapMode].\n\nCPU: registered at /pytorch/build/aten/src/ATen/RegisterCPU.cpp:5925 [kernel]\nCUDA: registered at /pytorch/build/aten/src/ATen/RegisterCUDA.cpp:7100 [kernel]\nQuantizedCPU: registered at /pytorch/build/aten/src/ATen/RegisterQuantizedCPU.cpp:641 [kernel]\nBackendSelect: fallthrough registered at /pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nNamed: registered at /pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nAutogradOther: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:9122 [autograd kernel]\nAutogradCPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:9122 [autograd kernel]\nAutogradCUDA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:9122 [autograd kernel]\nAutogradXLA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:9122 [autograd kernel]\nAutogradNestedTensor: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:9122 [autograd kernel]\nUNKNOWN_TENSOR_TYPE_ID: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:9122 [autograd kernel]\nAutogradPrivateUse1: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:9122 [autograd kernel]\nAutogradPrivateUse2: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:9122 [autograd kernel]\nAutogradPrivateUse3: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:9122 [autograd kernel]\nTracer: registered at /pytorch/torch/csrc/autograd/generated/TraceType_2.cpp:10525 [kernel]\nAutocast: registered at /pytorch/aten/src/ATen/autocast_mode.cpp:254 [kernel]\nBatched: registered at /pytorch/aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at /pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-cd7d4f7e50c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mcontig_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mconcat_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: There were no tensor arguments to this function (e.g., you passed an empty list of Tensors), but no fallback function is registered for schema aten::_cat.  This usually means that this function requires a non-empty list of Tensors.  Available functions are [CPU, CUDA, QuantizedCPU, BackendSelect, Named, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradNestedTensor, UNKNOWN_TENSOR_TYPE_ID, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, Autocast, Batched, VmapMode].\n\nCPU: registered at /pytorch/build/aten/src/ATen/RegisterCPU.cpp:5925 [kernel]\nCUDA: registered at /pytorch/build/aten/src/ATen/RegisterCUDA.cpp:7100 [kernel]\nQuantizedCPU: registered at /pytorch/build/aten/src/ATen/RegisterQuantizedCPU.cpp:641 [kernel]\nBackendSelect: fallthrough registered at /pytorch/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nNamed: registered at /pytorch/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nAutogradOther: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:9122 [autograd kernel]\nAutogradCPU: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:9122 [autograd kernel]\nAutogradCUDA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:9122 [autograd kernel]\nAutogradXLA: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:9122 [autograd kernel]\nAutogradNestedTensor: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:9122 [autograd kernel]\nUNKNOWN_TENSOR_TYPE_ID: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:9122 [autograd kernel]\nAutogradPrivateUse1: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:9122 [autograd kernel]\nAutogradPrivateUse2: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:9122 [autograd kernel]\nAutogradPrivateUse3: registered at /pytorch/torch/csrc/autograd/generated/VariableType_2.cpp:9122 [autograd kernel]\nTracer: registered at /pytorch/torch/csrc/autograd/generated/TraceType_2.cpp:10525 [kernel]\nAutocast: registered at /pytorch/aten/src/ATen/autocast_mode.cpp:254 [kernel]\nBatched: registered at /pytorch/aten/src/ATen/BatchingRegistrations.cpp:1016 [backend fallback]\nVmapMode: fallthrough registered at /pytorch/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\n"
     ]
    }
   ],
   "source": [
    "reference_path = '/mnt/data/CAMI/DNABERT/output/'\n",
    "\n",
    "tensors = []\n",
    "contig_names = []\n",
    "for filename in glob.glob('/mnt/data/CAMI/DNABERT/output/*.pickle'):\n",
    "    with open(filename, 'rb') as f:\n",
    "        x = pickle.load(f)\n",
    "        tensors.extend(list(x.values()))\n",
    "        contig_names.extend(list(x.keys()))\n",
    "concat_tensors = torch.cat(tensors,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "intelligent-friday",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy = '/mnt/data/CAMI/data/short_read_oral/taxonomy.tsv'\n",
    "contig_to_genome = '/mnt/data/CAMI/data/short_read_oral/reformatted_manually_combined_gsa_mapping.tsv'\n",
    "\n",
    "contig_to_genome_df = pd.read_csv(contig_to_genome, sep='\\t', header=None)\n",
    "contig_to_genome_df = contig_to_genome_df.rename(columns={0: 'contig_name', 1: 'genome'})\n",
    "\n",
    "taxonomy_df = pd.read_csv(taxonomy, sep='\\t', header = None)\n",
    "taxonomy_df = taxonomy_df.rename(columns={0: 'genome', 1: 'species', 2: 'genus'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7e104246",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple() takes at most 1 argument (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-53938746a957>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: tuple() takes at most 1 argument (2 given)"
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(contig_to_genome_df, taxonomy_df, how=\"left\", on=[\"genome\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "built-prague",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Streptococcus',\n",
       " 'Burkholderia',\n",
       " 'Campylobacter',\n",
       " 'Neisseria',\n",
       " 'Clostridioides',\n",
       " 'Haemophilus',\n",
       " 'Lactococcus',\n",
       " 'Flavobacterium',\n",
       " 'Pasteurella',\n",
       " 'Mannheimia']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_sample_6 = merged_df[merged_df['contig_name'].str.startswith('S6C')]\n",
    "set_sample_6 = set(merged_df_sample_6['species'])\n",
    "\n",
    "set_all_samples = set(merged_df['species'])\n",
    "diff = list(set_all_samples - set_sample_6)\n",
    "\n",
    "#print(diff)\n",
    "n = 10\n",
    "merged_df['genus'].value_counts()[:n].index.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "painful-listing",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/data/CAMI/DNABERT/contig_lengths.pickle'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8ffff70ada23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcontig_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/mnt/data/CAMI/DNABERT/contig_lengths.pickle\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontig_lengths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mcontig_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcontig_lengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontig_lengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/mnt/data/CAMI/DNABERT/contig_lengths.pickle'"
     ]
    }
   ],
   "source": [
    "contig_lengths = \"/mnt/data/CAMI/DNABERT/contig_lengths.pickle\"\n",
    "with open(contig_lengths,'rb') as f:\n",
    "    contig_lengths = pickle.load(f)\n",
    "    \n",
    "contig_lengths = {k[1:]: v for k, v in contig_lengths.items()}\n",
    "merged_df[\"contig_lengths\"] = merged_df[\"contig_name\"].map(contig_lengths)\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-olympus",
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_name_to_idx = {v[1:]: i for i, v in enumerate(contig_names)}\n",
    "merged_df[\"contig_idx\"] = merged_df[\"contig_name\"].apply(lambda x: contig_name_to_idx.get(x))\n",
    "non_aligned = ~merged_df[\"contig_idx\"].isnull()\n",
    "aligned_tensor_df = merged_df[non_aligned]\n",
    "aligned_tensor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "negative-associate",
   "metadata": {},
   "outputs": [],
   "source": [
    "column = aligned_tensor_df['contig_lengths']\n",
    "max_value = column.max()\n",
    "print(max_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "white-classic",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_tensor_index_df = aligned_tensor_df.astype({\"contig_idx\": int})\n",
    "aligned_tensor_index_df = aligned_tensor_index_df.set_index(\"contig_idx\").sort_index()\n",
    "aligned_tensor_index_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reliable-finding",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter all contigs > 512\n",
    "\n",
    "print(len(aligned_tensor_index_df))\n",
    "filtered_512_df = aligned_tensor_index_df[aligned_tensor_index_df[\"contig_lengths\"] < 512]\n",
    "print(len(filtered_512_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scientific-recycling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kmeans():\n",
    "    all_concat_np = concat_tensors.detach().numpy()\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(all_concat_np)\n",
    "    projection = pca.transform(all_concat_np)\n",
    "    \n",
    "    \n",
    "    from sklearn.cluster import KMeans\n",
    "    wcss = []\n",
    "    for i in range(100,700):\n",
    "        kmeans_pca = KMeans(n_clusters=i, init='k-means++', random_state=None)\n",
    "        kmeans_pca.fit(projection)\n",
    "        wcss.append(kmeans_pca.inertia_)\n",
    "\n",
    "    plt.plot(range(100,700), wcss, marker = 'o', linestyle = '--')\n",
    "    \n",
    "    #kmeans_pca = KMeans(n_clusters = 3, init = 'k-means++', random_state=None).fit(projection)\n",
    "    #print(kmeans_pca.cluster_centers_)\n",
    "    #print(kmeans_pca.inertia_)\n",
    "    \n",
    "    #from sklearn_extra.cluster import KMedoids\n",
    "    #ss = []\n",
    "    #for i in range(1,10):\n",
    "        #kmedoids_pca = KMedoids(n_clusters=2, random_state=0)\n",
    "        #kmedoids_pca.fit(projection)\n",
    "        #ss.append(kmedoids_pca.inertia_)\n",
    "    \n",
    "    #plt.plot(range(1,10), ss, marker = 'o', linestyle = '--')\n",
    "\n",
    "    #kmedoids_pca = KMedoids(n_clusters=2, random_state=0).fit(projection)\n",
    "    #print(kmedoids_pca.cluster_centers_)\n",
    "    #print(kmedoids_pca.inertia_)\n",
    "    \n",
    "plot_kmeans()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "sweet-anthropology",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filtered_512_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-d330af90fa6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgenome_group_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mgroups\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_512_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGROUP_KEY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'filtered_512_df' is not defined"
     ]
    }
   ],
   "source": [
    "MIN_SIZE_OF_GROUP = 100\n",
    "NUM_TO_GROUPS_TO_PLOT = 10\n",
    "GROUP_KEY = \"species\"\n",
    "\n",
    "genome_group_indices = []\n",
    "i = 0\n",
    "groups = list(filtered_512_df.groupby(GROUP_KEY))\n",
    "random.shuffle(groups)\n",
    "for x_name, x in groups:\n",
    "    if i >= 10:\n",
    "        break\n",
    "        \n",
    "    group_size = len(x)\n",
    "    if group_size < MIN_SIZE_OF_GROUP or group_size > 1000:\n",
    "        continue\n",
    "        \n",
    "    genome_group_indices.extend(x.index.tolist())\n",
    "    i += 1\n",
    "\n",
    "print(len(genome_group_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "liable-suite",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'concat_tensors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9741158d8399>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mplot_pca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-9741158d8399>\u001b[0m in \u001b[0;36mplot_pca\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplot_pca\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mall_concat_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcat_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mgenome_group_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_concat_np\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgenome_group_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'concat_tensors' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_pca():\n",
    "    all_concat_np = concat_tensors.detach().numpy()\n",
    "    genome_group_np = all_concat_np[genome_group_indices]\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(genome_group_np)\n",
    "    projection = pca.transform(genome_group_np)\n",
    "    \n",
    "    genome_to_color_id = {k: i for k, i in zip(filtered_512_df.loc[genome_group_indices][GROUP_KEY].unique(), range(10))}\n",
    "    print(genome_to_color_id.keys())\n",
    "    targets = filtered_512_df.loc[genome_group_indices][GROUP_KEY].apply(lambda x: genome_to_color_id[x]).tolist()\n",
    "    \n",
    "    labels = filtered_512_df.loc[genome_group_indices][GROUP_KEY].unique().tolist()\n",
    "    print(labels)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    scatter = plt.scatter(projection[:, 0], projection[:, 1], alpha=0.9, s=5.0, c=targets, cmap='tab10')\n",
    "    plt.legend(handles=scatter.legend_elements()[0], labels=labels)\n",
    "    \n",
    "plot_pca()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-acrylic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_kmeans():\n",
    "    all_concat_np = concat_tensors.detach().numpy()\n",
    "    genome_group_np = all_concat_np[genome_group_indices]\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(genome_group_np)\n",
    "    projection = pca.transform(genome_group_np)\n",
    "    \n",
    "    \n",
    "    from sklearn.cluster import KMeans\n",
    "    wcss = []\n",
    "    for i in range(1,10):\n",
    "        kmeans_pca = KMeans(n_clusters=i, init='k-means++', random_state=None)\n",
    "        kmeans_pca.fit(projection)\n",
    "        wcss.append(kmeans_pca.inertia_)\n",
    "\n",
    "    plt.plot(range(1,10), wcss, marker = 'o', linestyle = '--')\n",
    "    \n",
    "    kmeans_pca = KMeans(n_clusters = 3, init = 'k-means++', random_state=None).fit(projection)\n",
    "    print(kmeans_pca.cluster_centers_)\n",
    "    print(kmeans_pca.inertia_)\n",
    "    \n",
    "    from sklearn_extra.cluster import KMedoids\n",
    "    ss = []\n",
    "    for i in range(1,10):\n",
    "        kmedoids_pca = KMedoids(n_clusters=2, random_state=0)\n",
    "        kmedoids_pca.fit(projection)\n",
    "        ss.append(kmedoids_pca.inertia_)\n",
    "    \n",
    "    plt.plot(range(1,10), ss, marker = 'o', linestyle = '--')\n",
    "\n",
    "    kmedoids_pca = KMedoids(n_clusters=2, random_state=0).fit(projection)\n",
    "    print(kmedoids_pca.cluster_centers_)\n",
    "    print(kmedoids_pca.inertia_)\n",
    "    \n",
    "plot_kmeans()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-motivation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsne():    \n",
    "    all_concat_np = concat_tensors.detach().numpy()\n",
    "    genome_group_np = all_concat_np[genome_group_indices]\n",
    "    \n",
    "    #NUM_SUBSAMPLE = 10000\n",
    "    subsample_indices = list(range(len(genome_group_np)))\n",
    "    #random.shuffle(subsample_indices)\n",
    "    # subsample_indices =  subsample_indices[:NUM_SUBSAMPLE]\n",
    "    \n",
    "    subsampled_genome_groups_np = genome_group_np[subsample_indices]\n",
    "    tsne = TSNE(n_components=2, perplexity=30)\n",
    "    projection = tsne.fit_transform(subsampled_genome_groups_np)\n",
    "    \n",
    "    genome_to_color_id = {k: i for k, i in zip(filtered_512_df.loc[genome_group_indices].iloc[subsample_indices][GROUP_KEY].unique(), range(10))}\n",
    "    targets = filtered_512_df.loc[genome_group_indices].iloc[subsample_indices][GROUP_KEY].apply(lambda x: genome_to_color_id[x]).tolist()\n",
    "    labels = filtered_512_df.loc[genome_group_indices][GROUP_KEY].unique().tolist()\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    scatter = plt.scatter(projection[:, 0], projection[:, 1], alpha=0.9, s=3.0, c=targets, cmap='tab10')\n",
    "    plt.legend(handles=scatter.legend_elements()[0], labels=labels)\n",
    "\n",
    "plot_tsne()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entertaining-cooling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import vamb\n",
    "\n",
    "def create_contig_file_list(path_to_contig_file):\n",
    "    contig_list = []\n",
    "    with open(path_to_contig_file, 'r') as fp:\n",
    "        lines = fp.readlines()\n",
    "        for line in lines:\n",
    "            line = line.rstrip()\n",
    "            contig_list.append(line)\n",
    "    return contig_list\n",
    "\n",
    "mincontiglength=10\n",
    "contig_file_list='/mnt/data/CAMI/vamb/workflow/contigs.txt'\n",
    "file_list = create_contig_file_list(contig_file_list)\n",
    "\n",
    "tnfs_per_fasta = []\n",
    "contignames_per_fasta = []\n",
    "for fasta in file_list:\n",
    "    with vamb.vambtools.Reader(fasta, 'rb') as tnffile:\n",
    "        tnfs, contignames, contiglengths = vamb.parsecontigs.read_contigs(tnffile, minlength=mincontiglength)\n",
    "        tnfs_per_fasta.append(tnfs)\n",
    "        contignames_per_fasta.extend(contignames)\n",
    "\n",
    "tnfs_per_fasta = np.concatenate(tnfs_per_fasta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-apple",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(contignames_per_fasta))\n",
    "print(len(tnfs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varied-briefing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contignames to be sorted like filtered_512_df\n",
    "\n",
    "contig_name_to_idx = {v: i for i, v in enumerate(contignames_per_fasta)}\n",
    "vamb_aligned_tensor_df[\"contig_vamb_idx\"] = aligned_tensor_df[\"contig_name\"].map(contig_name_to_idx)\n",
    "vamb_aligned_tensor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-institute",
   "metadata": {},
   "outputs": [],
   "source": [
    "non_aligned = ~vamb_aligned_tensor_df[\"contig_vamb_idx\"].isnull()\n",
    "vam_aligned_reset_tensor_df = vamb_aligned_tensor_df[non_aligned]\n",
    "vamb_aligned_tensor_df = vamb_aligned_tensor_df.astype({\"contig_vamb_idx\": int})\n",
    "vamb_aligned_tensor_df = vamb_aligned_tensor_df.astype({\"contig_idx\": int})\n",
    "vamb_aligned_tensor_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "plain-mobile",
   "metadata": {},
   "outputs": [],
   "source": [
    "vamb_aligned_tensor_df_2 = vamb_aligned_tensor_df.set_index(\"contig_idx\").sort_index()\n",
    "vamb_aligned_tensor_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-junior",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(vamb_aligned_tensor_df))\n",
    "vamb_filtered_512_df = vamb_aligned_tensor_df_2[vamb_aligned_tensor_df_2[\"contig_lengths\"] < 512]\n",
    "\n",
    "print(len(vamb_filtered_512_df))\n",
    "vamb_filtered_512_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-snapshot",
   "metadata": {},
   "outputs": [],
   "source": [
    "MIN_SIZE_OF_GROUP = 100\n",
    "MAX_SIZE_OF_GROUP = 1000\n",
    "NUM_TO_GROUPS_TO_PLOT = 10\n",
    "GROUP_KEY = \"species\"\n",
    "\n",
    "genome_group_indices = []\n",
    "i = 0\n",
    "groups = list(vamb_filtered_512_df.groupby(GROUP_KEY))\n",
    "random.shuffle(groups)\n",
    "for x_name, x in groups:\n",
    "    if i >= 10:\n",
    "        break\n",
    "        \n",
    "    group_size = len(x)\n",
    "    if group_size < MIN_SIZE_OF_GROUP or group_size > MAX_SIZE_OF_GROUP:\n",
    "        continue\n",
    "        \n",
    "    genome_group_indices.extend(x.index.tolist())\n",
    "    i += 1\n",
    "\n",
    "print(len(genome_group_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "responsible-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pca_matrix(matrix):\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(matrix)\n",
    "    projection = pca.transform(matrix)\n",
    "    \n",
    "    genome_to_color_id = {k: i for k, i in zip(vamb_filtered_512_df.loc[genome_group_indices][GROUP_KEY].unique(), range(10))}\n",
    "    targets = vamb_filtered_512_df.loc[genome_group_indices][GROUP_KEY].apply(lambda x: genome_to_color_id[x]).tolist()\n",
    "    labels = vamb_filtered_512_df.loc[genome_group_indices][GROUP_KEY].unique().tolist()\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    scatter = plt.scatter(projection[:, 0], projection[:, 1], alpha=0.9, s=5.0, c=targets, cmap='tab10')\n",
    "    plt.legend(handles=scatter.legend_elements()[0], labels=labels)\n",
    "\n",
    "tnf_matrix = tnfs_per_fasta[vamb_filtered_512_df.loc[genome_group_indices][\"contig_vamb_idx\"].tolist()]\n",
    "plot_pca_matrix(tnf_matrix)\n",
    "\n",
    "all_concat_np = concat_tensors.detach().numpy()\n",
    "genome_group_np = all_concat_np[genome_group_indices]\n",
    "plot_pca_matrix(genome_group_np)\n",
    "\n",
    "tnf_matrix = (tnf_matrix) / (tnf_matrix.std())\n",
    "genome_group_np = (genome_group_np) / (genome_group_np.std())\n",
    "\n",
    "cat_tnf_dna = np.concatenate([genome_group_np, tnf_matrix], axis=-1)\n",
    "plot_pca_matrix(cat_tnf_dna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "super-framing",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_tsne_matrix(matrix):    \n",
    "    tsne = TSNE(n_components=2, perplexity=30)\n",
    "    projection = tsne.fit_transform(matrix)\n",
    "    \n",
    "    genome_to_color_id = {k: i for k, i in zip(vamb_filtered_512_df.loc[genome_group_indices][GROUP_KEY].unique(), range(10))}\n",
    "    targets = vamb_filtered_512_df.loc[genome_group_indices][GROUP_KEY].apply(lambda x: genome_to_color_id[x]).tolist()\n",
    "    labels = vamb_filtered_512_df.loc[genome_group_indices][GROUP_KEY].unique().tolist()\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    scatter = plt.scatter(projection[:, 0], projection[:, 1], alpha=0.9, s=3.0, c=targets, cmap='tab10')\n",
    "    plt.legend(handles=scatter.legend_elements()[0], labels=labels)\n",
    "\n",
    "tnf_matrix = tnfs_per_fasta[vamb_filtered_512_df.loc[genome_group_indices][\"contig_vamb_idx\"].tolist()]\n",
    "plot_tsne_matrix(tnf_matrix)\n",
    "\n",
    "all_concat_np = concat_tensors.detach().numpy()\n",
    "genome_group_np = all_concat_np[genome_group_indices]\n",
    "plot_tsne_matrix(genome_group_np)\n",
    "\n",
    "tnf_matrix = (tnf_matrix) / (tnf_matrix.std())\n",
    "genome_group_np = (genome_group_np) / (genome_group_np.std())\n",
    "cat_tnf_dna = np.concatenate([genome_group_np, tnf_matrix], axis=-1)\n",
    "plot_tsne_matrix(cat_tnf_dna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "careful-france",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.load('/mnt/data/CAMI/DNABERT/pretrained_models/4-new-12w-0/pytorch_model.bin', map_location=torch.device('cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-subcommittee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-bulgaria",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from transformers import BertTokenizer, BertforSequenceClassification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
